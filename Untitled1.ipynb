{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sys\n",
    "from keras import backend as K\n",
    "import warnings\n",
    "# Keras Core\n",
    "import keras\n",
    "from keras.layers.convolutional import MaxPooling2D, Convolution2D, AveragePooling2D\n",
    "from keras.layers import Input, Dropout, Dense, Flatten, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "# Backend\n",
    "from keras import backend as K\n",
    "# Utils\n",
    "from keras.utils.layer_utils import convert_all_kernels_in_model\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "\n",
    "def conv2d_bn(x, nb_filter, num_row, num_col,\n",
    "              padding='same', strides=(1, 1), use_bias=False):\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "    x = Convolution2D(nb_filter, (num_row, num_col),\n",
    "                      strides=strides,\n",
    "                      padding=padding,\n",
    "                      use_bias=use_bias)(x)\n",
    "    x = BatchNormalization(axis=channel_axis, scale=False)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def block_inception_a(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 96, 1, 1)\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 64, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 96, 3, 3)\n",
    "\n",
    "    branch_2 = conv2d_bn(input, 64, 1, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 96, 3, 3)\n",
    "    branch_2 = conv2d_bn(branch_2, 96, 3, 3)\n",
    "\n",
    "    branch_3 = AveragePooling2D((3,3), strides=(1,1), padding='same')(input)\n",
    "    branch_3 = conv2d_bn(branch_3, 96, 1, 1)\n",
    "\n",
    "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block_reduction_a(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 384, 3, 3, strides=(2,2), padding='valid')\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 192, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 224, 3, 3)\n",
    "    branch_1 = conv2d_bn(branch_1, 256, 3, 3, strides=(2,2), padding='valid')\n",
    "\n",
    "    branch_2 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(input)\n",
    "\n",
    "    x = concatenate([branch_0, branch_1, branch_2], axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block_inception_b(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 384, 1, 1)\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 192, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 224, 1, 7)\n",
    "    branch_1 = conv2d_bn(branch_1, 256, 7, 1)\n",
    "\n",
    "    branch_2 = conv2d_bn(input, 192, 1, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 192, 7, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 224, 1, 7)\n",
    "    branch_2 = conv2d_bn(branch_2, 224, 7, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 256, 1, 7)\n",
    "\n",
    "    branch_3 = AveragePooling2D((3,3), strides=(1,1), padding='same')(input)\n",
    "    branch_3 = conv2d_bn(branch_3, 128, 1, 1)\n",
    "\n",
    "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block_reduction_b(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 192, 1, 1)\n",
    "    branch_0 = conv2d_bn(branch_0, 192, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 256, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 256, 1, 7)\n",
    "    branch_1 = conv2d_bn(branch_1, 320, 7, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 320, 3, 3, strides=(2,2), padding='valid')\n",
    "\n",
    "    branch_2 = MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(input)\n",
    "\n",
    "    x = concatenate([branch_0, branch_1, branch_2], axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block_inception_c(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 256, 1, 1)\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 384, 1, 1)\n",
    "    branch_10 = conv2d_bn(branch_1, 256, 1, 3)\n",
    "    branch_11 = conv2d_bn(branch_1, 256, 3, 1)\n",
    "    branch_1 = concatenate([branch_10, branch_11], axis=channel_axis)\n",
    "\n",
    "\n",
    "    branch_2 = conv2d_bn(input, 384, 1, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 448, 3, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 512, 1, 3)\n",
    "    branch_20 = conv2d_bn(branch_2, 256, 1, 3)\n",
    "    branch_21 = conv2d_bn(branch_2, 256, 3, 1)\n",
    "    branch_2 = concatenate([branch_20, branch_21], axis=channel_axis)\n",
    "\n",
    "    branch_3 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(input)\n",
    "    branch_3 = conv2d_bn(branch_3, 256, 1, 1)\n",
    "\n",
    "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def inception_v4_base(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    # Input Shape is 256 x 256 x 3 (th) or 3 x 256 x 256 (th)\n",
    "    net = conv2d_bn(input, 32, 3, 3, strides=(2,2), padding='valid')\n",
    "    net = conv2d_bn(net, 32, 3, 3, padding='valid')\n",
    "    net = conv2d_bn(net, 64, 3, 3)\n",
    "\n",
    "    branch_0 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(net)\n",
    "\n",
    "    branch_1 = conv2d_bn(net, 96, 3, 3, strides=(2,2), padding='valid')\n",
    "\n",
    "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
    "\n",
    "    branch_0 = conv2d_bn(net, 64, 1, 1)\n",
    "    branch_0 = conv2d_bn(branch_0, 96, 3, 3, padding='valid')\n",
    "\n",
    "    branch_1 = conv2d_bn(net, 64, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 64, 1, 7)\n",
    "    branch_1 = conv2d_bn(branch_1, 64, 7, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 96, 3, 3, padding='valid')\n",
    "\n",
    "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
    "\n",
    "    branch_0 = conv2d_bn(net, 192, 3, 3, strides=(2,2), padding='valid')\n",
    "    branch_1 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(net)\n",
    "\n",
    "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
    "\n",
    "    # 35 x 35 x 384\n",
    "    # 4 x Inception-A blocks\n",
    "    for idx in range(4):\n",
    "    \tnet = block_inception_a(net)\n",
    "\n",
    "    # 35 x 35 x 384\n",
    "    # Reduction-A block\n",
    "    net = block_reduction_a(net)\n",
    "\n",
    "    # 17 x 17 x 1024\n",
    "    # 7 x Inception-B blocks\n",
    "    for idx in range(7):\n",
    "    \tnet = block_inception_b(net)\n",
    "\n",
    "    # 17 x 17 x 1024\n",
    "    # Reduction-B block\n",
    "    net = block_reduction_b(net)\n",
    "\n",
    "    # 8 x 8 x 1536\n",
    "    # 3 x Inception-C blocks\n",
    "    for idx in range(3):\n",
    "    \tnet = block_inception_c(net)\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "def inception_v4(num_classes, dropout_keep_prob, weights, include_top):\n",
    "\n",
    "\n",
    "    # Input Shape is 256 x 256 x 3 (tf) or 3 x 256 x 256 (th)\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        inputs = Input((3, 256, 256))\n",
    "    else:\n",
    "        inputs = Input((256, 256, 3))\n",
    "\n",
    "    # Make inception base\n",
    "    x = inception_v4_base(inputs)\n",
    "\n",
    "\n",
    "    # Final pooling and prediction\n",
    "\n",
    "    if include_top:\n",
    "        # 1 x 1 x 1536\n",
    "        x = AveragePooling2D((6,6), padding='valid')(x)\n",
    "        x = Dropout(dropout_keep_prob)(x)\n",
    "        x = Flatten()(x)\n",
    "        # 1536\n",
    "        x = Dense(units=num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, x, name='inception_v4')\n",
    "\n",
    "    # load weights\n",
    "#     if weights == 'imagenet':\n",
    "#         if K.image_data_format() == 'channels_first':\n",
    "#             if K.backend() == 'tensorflow':\n",
    "#                 warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "#                               'are using the Theano '\n",
    "#                               'image data format convention '\n",
    "#                               '(`image_data_format=\"channels_first\"`). '\n",
    "#                               'For best performance, set '\n",
    "#                               '`image_data_format=\"channels_last\"` in '\n",
    "#                               'your Keras config '\n",
    "#                               'at ~/.keras/keras.json.')\n",
    "#         if include_top:\n",
    "#             weights_path = get_file(\n",
    "#                 'inception-v4_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "#                 WEIGHTS_PATH,\n",
    "#                 cache_subdir='models')\n",
    "#         else:\n",
    "#             weights_path = get_file(\n",
    "#                 'inception-v4_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "#                 WEIGHTS_PATH_NO_TOP,\n",
    "#                 cache_subdir='models')\n",
    "#         model.load_weights(weights_path, by_name=True)\n",
    "#         if K.backend() == 'theano':\n",
    "#             warnings.warn('The Theano backend is not currently supported for '\n",
    "#             \t\t\t  'this model on Keras 2. Please use the TensorFlow  '\n",
    "#             \t\t\t  'backend or you will get bad results!')\n",
    "    return model\n",
    "\n",
    "def create_model(num_classes=20, dropout_prob=0.2, weights=None, include_top=True):\n",
    "\treturn inception_v4(num_classes, dropout_prob, weights, include_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/home/team4/TW/TW_inception_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from glob import glob \n",
    "\n",
    "# output = glob('./train/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"./train/train.tsv\", delimiter='\\t', header=None)\n",
    "testset = pd.read_csv(\"./test/test.tsv\", delimiter='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 라벨 대치\n",
    "# dict = {\n",
    "#     8:0,\n",
    "#     23:1,\n",
    "#     6:2,\n",
    "#     11:3,\n",
    "#     15:4,\n",
    "#     13:5,\n",
    "#     82:6,\n",
    "#     27:7,\n",
    "#     14:8,\n",
    "#     17:9,\n",
    "#     30:10,\n",
    "#     25:11,\n",
    "#     142:12,\n",
    "#     19:13,\n",
    "#     22:14,\n",
    "#     28:15,\n",
    "#     29:16,\n",
    "#     302:17,\n",
    "#     31:18,\n",
    "#     33:19   \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_list = list()\n",
    "# for i in range(len(output)) :\n",
    "#     plant,disease =map(int,output[i].split('/')[2].split('_'))\n",
    "#     if (plant+disease) == 8 :\n",
    "#         if plant == 3 :\n",
    "#             label_list.append(dict[8])\n",
    "#         else :\n",
    "#             label_list.append(dict[82])\n",
    "#     elif (plant+disease) == 14 :\n",
    "#         if plant == 8 :\n",
    "#             label_list.append(dict[14])\n",
    "#         else :\n",
    "#             label_list.append(dict[142])\n",
    "#     elif (plant+disease) == 30 :\n",
    "#         if plant == 10 :\n",
    "#             label_list.append(dict[30])\n",
    "#         else :\n",
    "#             label_list.append(dict[302])\n",
    "#     else:\n",
    "#         label_list.append(dict[plant+disease])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = np.load('/home/team4/TW/train_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_data = np.load('/home/team4/TW/val_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = np.load('/home/team4/TW/test_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data = np.load('/home/team4/TW/result_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_label = np.load('/home/team4/TW/result_label.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_data =np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_label = to_categorical(label_data)\n",
    "# test_label = to_categorical(label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(output, test_label , test_size=0.3, random_state=444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, Ap, X_val, Mp = train_test_split(X_train, y_train , test_size=0.3, random_state=444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-0248d630cb01>:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for image in tqdm_notebook(range(1,len(X_train))) :\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030333ef864b4684b66a83db3b6f64df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7839.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# import PIL.Image as pilimg\n",
    "# from tqdm import tqdm_notebook\n",
    "# train_data = pilimg.open(X_train[0])\n",
    "# train_data = np.array(train_data)\n",
    "# train_data = train_data.reshape(1,train_data.shape[0],train_data.shape[1],train_data.shape[2]) \n",
    "# # with tf.device('/device:GPU:0'):\n",
    "# for image in tqdm_notebook(range(1,len(X_train))) :\n",
    "#     a = pilimg.open(X_train[image])\n",
    "#     temp = np.array(a)\n",
    "#     temp =temp.reshape(1,temp.shape[0],temp.shape[1],temp.shape[2])\n",
    "#     train_data=np.append(train_data,temp,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-0920276399a3>:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for image in tqdm_notebook(range(1,len(Ap))) :\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29cbf4eeec96459080c4a6786cc8a08f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3359.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# import PIL.Image as pilimg\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# test_data = pilimg.open(Ap[0])\n",
    "# test_data = np.array(test_data)\n",
    "# test_data = test_data.reshape(1,test_data.shape[0],test_data.shape[1],test_data.shape[2]) \n",
    "# # with tf.device('/device:GPU:0'):\n",
    "# for image in tqdm_notebook(range(1,len(Ap))) :\n",
    "#     a = pilimg.open(Ap[image])\n",
    "#     temp = np.array(a)\n",
    "#     temp =temp.reshape(1,temp.shape[0],temp.shape[1],temp.shape[2])\n",
    "#     test_data=np.append(test_data,temp,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_data = np.concatenate((train_data, test_data),axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_label = np.concatenate((X_val, Mp), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_data = np.concatenate((result_data, val_data) , axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_label = np.concatenate((result_label, y_test), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save( '/home/team4/TW/result_label',result_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 256, 256, 3), (16000, 20))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_data.shape , result_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(result_data, result_label , test_size=0.3, random_state=444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11200, 256, 256, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "             optimizer='rmsprop',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    history = model.fit(X_train2,\n",
    "                        y_train2,\n",
    "                        epochs=1,\n",
    "                        batch_size=128,\n",
    "                        validation_data=(X_test2,y_test2)\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-45-e9a067d61791>:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for image in tqdm_notebook(range(1,len(X_test))) :\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c09395e9c94b91acebec428d3a2ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4799.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# val_data = pilimg.open(X_test[0])\n",
    "# val_data = np.array(val_data)\n",
    "# val_data = val_data.reshape(1,val_data.shape[0],val_data.shape[1],val_data.shape[2]) \n",
    "# # with tf.device('/device:GPU:0'):\n",
    "# for image in tqdm_notebook(range(1,len(X_test))) :\n",
    "#     a = pilimg.open(X_test[image])\n",
    "#     temp = np.array(a)\n",
    "#     temp =temp.reshape(1,temp.shape[0],temp.shape[1],temp.shape[2])\n",
    "#     val_data=np.append(val_data,temp,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 543s 1s/step - loss: 2.4737 - accuracy: 0.7364\n",
      "[2.473668098449707, 0.7364374995231628]\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(result_data, result_label, batch_size= 32)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save( '/home/team4/TW/test_data',test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Accuracy graph \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "loss_ax.plot(history.history['accuracy'], 'b', label='train accuracy')\n",
    "loss_ax.plot(history.history['loss'], 'r', label='test accuracy')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('accuracy')\n",
    "\n",
    "loss_ax.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save('TW_inception_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 모델 사용하기\n",
    "xhat_idx = np.random.choice(x_test.shape[0], 5)\n",
    "xhat = x_test[xhat_idx]\n",
    "yhat = model.predict_classes(xhat)\n",
    "\n",
    "for i in range(5):\n",
    "    print('True : ' + str(argmax(y_test[xhat_idx[i]])) + ', Predict : ' + str(yhat[i]))\n",
    "    \n",
    "    \n",
    "\n",
    "    # 100세대 학습 => 1세대당 390번 반복\n",
    "# 학습\n",
    "batch_size = 128\n",
    "# 학습 이력이 리턴됨\n",
    "history = model.fit_generator(\n",
    "    # 훈련 데이터\n",
    "    train_gen.flow(train_images, train_labels, batch_size=batch_size),\n",
    "    epochs          = 10, #100, 시간강 줄임, 실제는 100세대 진행\n",
    "    # 이 항목을 지정해야함, validation_steps가 유효함 -> 390\n",
    "    steps_per_epoch = train_images.shape[0] // batch_size,\n",
    "    # 검증 데이터 => generator\n",
    "    validation_data = test_gen.flow(test_images, test_labels, batch_size=batch_size),\n",
    "    # 검증 1회당 이폭수 -> 390\n",
    "    validation_steps= test_images.shape[0] // batch_size,\n",
    "    # 훈련시 콜백함수\n",
    "    callbacks       =[lr_decay])\n",
    "\n",
    "\n",
    "# 데이터셋 전처리\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "\n",
    "# 6. 모델 저장하기\n",
    "from keras.models import load_model\n",
    "model.save('TW_inception_model.h5')\n",
    "\n",
    "\n",
    "# model arc\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n",
    "\n",
    "# 2. 모델 불러오기\n",
    "from keras.models import load_model\n",
    "model = load_model('mnist_mlp_model.h5')\n",
    "\n",
    "# 3. 모델 사용하기\n",
    "yhat = model.predict_classes(xhat)\n",
    "\n",
    "for i in range(5):\n",
    "    print('True : ' + str(argmax(y_test[xhat_idx[i]])) + ', Predict : ' + str(yhat[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
